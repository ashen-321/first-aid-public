from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, ToolMessage
from langchain_mcp_adapters.tools import load_mcp_tools
import os
import re
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from asyncio import run
from openai import OpenAI

from agent_protocol import MultiAgentState


# --------------------------------------------------------------------------------------------
# Config -------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------


config = {
    'model_id': "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
    'max_search_results': 5
}

def set_tool_config(options: dict):
    for key in options:
        config[key] = options[key]


# --------------------------------------------------------------------------------------------
# Helper Functions ---------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------


def openai_url_invoke(model_id: str, prompt: str, service_url: str = 'http://agent.cavatar.info:8081/v1', max_token: int = 10240, temperature: float = 0.05, top_p: float = 0.9, top_k: int = 20):
    print(f'\n--- Invoking model "{model_id}" from "{service_url}" ---\n')
    
    openai_api_base = service_url
    
    client = OpenAI(
        base_url=openai_api_base,
    )

    chat_response = client.chat.completions.create(
        model=model_id,
        messages=[
            {"role": "system", "content": 'You are a seasoned medical expert. Your role is to determine the quality of the answer generated by a team of other AI models. Output "GOOD" if the response matches truth and real world advice, otherwise output "BAD". Do not output anything else besides those two options. Output in all capital letters.'},
            {"role": "user", "content": prompt}
        ],
        stream=False,
        temperature=temperature,
        max_tokens=max_token,
        top_p=top_p
    )
    footer = f'Completion_tokens: {chat_response.usage.completion_tokens}, Prompt_tokens: {chat_response.usage.prompt_tokens},  Total_tokens:{chat_response.usage.total_tokens}'
    return chat_response.choices[0].message.content, footer


# --------------------------------------------------------------------------------------------
# Tools --------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------


tavily_search = TavilySearchResults(max_results=config['max_search_results'], tavily_api_key=os.getenv("tavily_api_token"))


server_params_pubmed = StdioServerParameters(
    command="/home/aaron/.conda/envs/firstaid/bin/python",
    args=["/home/aaron/src/first-aid/demo/firstaid/backend/scripts/pubmed/server.py"],
    transport="stdio",
)


server_params_medrxiv = StdioServerParameters(
    command="/home/aaron/.conda/envs/firstaid/bin/python",
    args=["/home/aaron/src/first-aid/demo/firstaid/backend/scripts/medrxiv/medrxiv_server.py"],
    transport="stdio",
)

null = None


async def pubmed_node(state: MultiAgentState):
    print(f'\n--- TOOL: Searching PubMed ---\n')
    
    async with stdio_client(server_params_pubmed) as (read, write):
        async with ClientSession(read, write) as session:
            llm = ChatOpenAI(
                model=config['model_id'],
                temperature=0.5,
                max_tokens=None,
                timeout=None,
                max_retries=5,
            )
            
            # Initialize the connection
            await session.initialize()
    
            # Get tools
            tools = await load_mcp_tools(session)
    
            # Create and run the agent
            agent = create_react_agent(llm, tools, checkpointer=MemorySaver())
            response = await agent.ainvoke({'messages': {'role': 'user', 'content': state['rewritten_question'] + f"\n\n Use {config['max_search_results']} search results."}})
            response = response['messages']

            # Parse output for URLs and text
            urls = []
            info = []
            for message in response:
                if not isinstance(message, ToolMessage):
                    continue

                # content = re.sub("\'", "", message.content)\
                try:
                    content = eval(message.content)
                except:
                    print(f'eval FAILED - \n\n{message.content}')
                    pass
                # print(f"\nPubMed result: {content}\n\n")

                # Result is a list of sources
                for source in content:
                    urls.append(source['pubmed_url'])
                    info.append(source['abstract'])

            # Return raw info, AI summary, and URLs
            state['external_data'].extend(info)
            state['external_summaries'].append(response[-1].content)
            state['data_sources'].extend(urls)

            return {}


async def medrxiv_node(state: MultiAgentState):
    print(f'\n--- TOOL: Searching MedRXIV ---\n')
    
    async with stdio_client(server_params_medrxiv) as (read, write):
        async with ClientSession(read, write) as session:
            llm = ChatOpenAI(
                model=config['model_id'],
                temperature=0.5,
                max_tokens=None,
                timeout=None,
                max_retries=5,
            )
            
            # Initialize the connection
            await session.initialize()
    
            # Get tools
            tools = await load_mcp_tools(session)
    
            # Create and run the agent
            agent = create_react_agent(llm, tools, checkpointer=MemorySaver())
            response = await agent.ainvoke({'messages': {'role': 'user', 'content': state['rewritten_question'] + f"\n\n Use {config['max_search_results']} search results."}})
            response = response['messages']

            # Parse output for URLs and text
            urls = []
            info = []
            for message in response:
                if not isinstance(message, ToolMessage):
                    continue
                
                content = eval(message.content)
                # print(f"\nMedrxiv result: {content}\n\n")

                # Content can be dict (1 source) or list (one or multiple sources)
                if isinstance(content, dict):
                    if 'Link' in content:
                        urls.append(content['Link'])
                        info.append(content['Abstract'])
                else:
                    for source in content:
                        source = eval(source)

                        # Ignore elements if they aren't actual sources
                        if 'Link' not in source:
                            pass
                                
                        urls.append(source['Link'])
                        info.append(source['Abstract'])

            # Return raw info, AI summary, and URLs
            state['external_data'].extend(info)
            state['external_summaries'].append(response[-1].content)
            state['data_sources'].extend(urls)

            return {}

async def web_search_node(state: MultiAgentState):
    print(f'\n--- TOOL: Searching web ---\n')
    
    # Create LLM
    llm = ChatOpenAI(
        model=config['model_id'],
        temperature=0.5,
        max_tokens=None,
        timeout=None,
        max_retries=5,
    )

    # Create react agent
    research_agent = create_react_agent(
        llm,
        tools=[tavily_search],
        checkpointer=MemorySaver(),
        prompt="You are a medical expert working with other medical experts to answer first aid questions. Your role is to research from the internet and collect relevant information from sources.\n\n" + state['rewritten_question'],
    )

    # Get agent response
    response = await research_agent.ainvoke({'messages': {'role': 'user', 'content': state['rewritten_question'] + f"\n\n Use {config['max_search_results']} search results."}})
    response = response['messages']

    # Parse output for URLs and text
    urls = []
    info = []
    for message in response:
        if not isinstance(message, ToolMessage):
            continue

        content = eval(message.content)
        for source in content:
            urls.append(source['url'])
            info.append(source['content'])

    # Return raw info, AI summary, and URLs
    state['external_data'].extend(info)
    state['external_summaries'].append(response[-1].content)
    state['data_sources'].extend(urls)
    
    return {}


async def main():
    await medrxiv_node({})

if __name__ == "__main__":
    run(main())
